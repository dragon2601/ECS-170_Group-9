{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c709f7-33c2-4d4e-b303-f417123e6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Hangman Class\n",
    "class Hangman:\n",
    "    def __init__(self):\n",
    "        self.guesses = set()\n",
    "        self.state = []\n",
    "\n",
    "    def update_state(self, letter: str, positions: list):\n",
    "        for pos in positions:\n",
    "            self.state[pos] = letter\n",
    "        self.guesses.add(letter)\n",
    "\n",
    "    def get_state(self) -> str:\n",
    "        return ''.join(self.state)\n",
    "\n",
    "# Entropy-Based AI Player\n",
    "class EntropyBasedPlayer:\n",
    "    def __init__(self, word_database):\n",
    "        self.word_database = word_database\n",
    "        \n",
    "    # Conditional entropy is used to calculate probablistic likelyhood of getting a letter correct: \n",
    "    # The entropy H(X) serves as a measure of the uncertainty or randomness associated with the outcomes of the random variable X. \n",
    "    # The entropy \\( H(X) \\) of a discrete random variable \\( X \\) is defined as:\n",
    "    # \\[\n",
    "    # H(X) = -\\sum_{x \\in \\mathcal{X}} p(x) \\log_2 p(x)\n",
    "    # \\]\n",
    "    # where \\( \\mathcal{X} \\) is the set of all possible values that \\( X \\) can take, and \\( p(x) \\) is \n",
    "    # the probability mass function of \\( X \\).\n",
    "    def calculate_entropy(self, frequency_distribution):\n",
    "        total = sum(frequency_distribution.values())\n",
    "        entropy = -sum((count / total) * math.log2(count / total) for count in frequency_distribution.values())\n",
    "        return entropy\n",
    "\n",
    "    \n",
    "    # We are going to set filtered_words to the entire database to finally eliminate the words that do not match the criterium:\n",
    "    # Lenght of words\n",
    "    # Letters and their corresponding positions\n",
    "    # If only one word fits the criteria, guess the entired word\n",
    "    # Guess the most likely letter (the one with tthe lowest entropy) \n",
    "    def next_guess(self, current_state, previous_guesses):\n",
    "        filtered_words = self.word_database\n",
    "\n",
    "        # Filtering by length first\n",
    "        if len(current_state) > 0:\n",
    "            filtered_words = [word for word in filtered_words if len(word) == len(current_state)]\n",
    "        \n",
    "        # Further filtering based on known letters\n",
    "        for i, char in enumerate(current_state):\n",
    "            if char != \"_\":\n",
    "                filtered_words = [word for word in filtered_words if word[i] == char]\n",
    "                \n",
    "        # If only one word is left, guess the entire word\n",
    "        if len(filtered_words) == 1:\n",
    "            return filtered_words[0]\n",
    "\n",
    "        # Calculating letter frequencies and entropies:\n",
    "        # \"\".join(filtered_words): This part concatenates all the words in filtered_words into a single long string.\n",
    "        # Counter(...): This uses Python's collections.Counter to count the occurrences of each letter in that long string. \n",
    "        # The result is stored in a dictionary-like object frequency_distribution where the keys are the unique letters and \n",
    "        # the values are the frequencies of these letters.\n",
    "        # For example, if filtered_words = [\"apple\", \"banana\"], then the frequency_distribution would \n",
    "        # look like {'a': 4, 'p': 2, 'l': 1, 'e': 1, 'b': 1, 'n': 2}.\n",
    "        frequency_distribution = Counter(\"\".join(filtered_words))\n",
    "        \n",
    "        # This loop iterates through each character in current_state, which is the current revealed state of \n",
    "        # the word (e.g., \"_ppl_\" for \"apple\").\n",
    "        # If a character (that is not an underscore _) appears in frequency_distribution, it is eliminated. \n",
    "        # This ensures that the AI does not guess a letter it has already guessed or that has already been revealed.\n",
    "        for guessed in current_state:\n",
    "            if guessed in frequency_distribution:\n",
    "                del frequency_distribution[guessed]\n",
    "        \n",
    "        # This will prevent the AI from guessing the same letter repeatedly\n",
    "        for guessed in previous_guesses:\n",
    "            if guessed in frequency_distribution:\n",
    "                del frequency_distribution[guessed]\n",
    "                \n",
    "        # This checks if frequency_distribution is empty. If it is, the function returns None, which would happen \n",
    "        # if all possible letters have already been guessed or revealed, leaving the AI with no more options for guessing\n",
    "        if not frequency_distribution:\n",
    "            return None\n",
    "\n",
    "        # Guessing the letter with the lowest entropy (the most likely letter based on entropy criteria)\n",
    "        # Notice that self.calculate_entropy computes entropy\n",
    "        min_entropy_letter = min(frequency_distribution, key=lambda x: self.calculate_entropy({x: frequency_distribution[x]})) \n",
    "        return min_entropy_letter\n",
    "\n",
    "# A sample word database which replace with actual database later)\n",
    "word_database = [\"WELLMAN HALL\", \"ARC\", \"YOUNG HALL\", \"KEMPER HALL\", \"AGGIES\", \"GO AGS\", \"PAVILLION\", \"eureka\", \"mathematics\", \"physics\"]\n",
    "\n",
    "# Initializing game and AI player\n",
    "hangman = Hangman()\n",
    "player = EntropyBasedPlayer(word_database)\n",
    "\n",
    "\n",
    "# Game \n",
    "while True:\n",
    "    if hangman.get_state():\n",
    "        print(f\"Current state: {hangman.get_state()}\")\n",
    "\n",
    "    next_guess = player.next_guess(hangman.get_state(), hangman.guesses)\n",
    "\n",
    "    if next_guess and len(next_guess) > 1:\n",
    "        print(f\"AI guesses the entire word: {next_guess}\")\n",
    "        is_correct = input(\"Is the AI correct? (y/n): \").strip().lower() == 'y'\n",
    "        if is_correct:\n",
    "            print(\"AI won!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"AI was wrong.\")\n",
    "            break\n",
    "\n",
    "    if next_guess is None:\n",
    "        print(\"AI gives up.\")\n",
    "        break\n",
    "\n",
    "    print(f\"AI guesses: {next_guess}\")\n",
    "\n",
    "    is_correct = input(f\"Is the guess correct? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "    if is_correct:\n",
    "        if not hangman.state:\n",
    "            word_length = int(input(\"Enter the length of the word: \"))\n",
    "            hangman.state = [\"_\"] * word_length\n",
    "        positions = list(map(int, input(\"Enter the positions (0-based) of the letter, separated by spaces: \").split()))\n",
    "        hangman.update_state(next_guess, positions)\n",
    "    else:\n",
    "        hangman.guesses.add(next_guess)\n",
    "        print(\"Guess is incorrect.\")\n",
    "\n",
    "    if hangman.state and \"_\" not in hangman.get_state():\n",
    "        print(\"AI won!\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
